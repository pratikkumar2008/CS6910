{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DL-Assignment3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "873353a398f64445a8c708575addca68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_45810182e2454462804fba3d4cad252e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_484dd557428a42398d257c1d56fc86c6",
              "IPY_MODEL_6b8abdac093d4a6b8168913eda52d321"
            ]
          }
        },
        "45810182e2454462804fba3d4cad252e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "484dd557428a42398d257c1d56fc86c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_cb1969c6569543749443e1ed0f5adf13",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 19.32MB of 19.32MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c5e17da8c754e2b8c8c53e97ca2cd95"
          }
        },
        "6b8abdac093d4a6b8168913eda52d321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4843974f48e0493d876241cad175035e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17773eb6051f4c7b935210fb1a3915fd"
          }
        },
        "cb1969c6569543749443e1ed0f5adf13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c5e17da8c754e2b8c8c53e97ca2cd95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4843974f48e0493d876241cad175035e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17773eb6051f4c7b935210fb1a3915fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acfefd48",
        "outputId": "e074122d-9ebf-4b82-c965-3522b07ddb8c"
      },
      "source": [
        "!pip install wandb\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "id": "acfefd48",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/5f/45439b4767334b868e1c8c35b1b0ba3747d8c21be77b79f09eed7aa3c72b/wandb-0.10.30-py2.py3-none-any.whl (1.8MB)\n",
            "\r\u001b[K     |▏                               | 10kB 13.1MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 18.1MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 14.8MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 14.0MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 8.5MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 9.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 71kB 8.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81kB 9.2MB/s eta 0:00:01\r\u001b[K     |█▋                              | 92kB 9.8MB/s eta 0:00:01\r\u001b[K     |█▉                              | 102kB 7.9MB/s eta 0:00:01\r\u001b[K     |██                              | 112kB 7.9MB/s eta 0:00:01\r\u001b[K     |██▏                             | 122kB 7.9MB/s eta 0:00:01\r\u001b[K     |██▍                             | 133kB 7.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 143kB 7.9MB/s eta 0:00:01\r\u001b[K     |██▊                             | 153kB 7.9MB/s eta 0:00:01\r\u001b[K     |███                             | 163kB 7.9MB/s eta 0:00:01\r\u001b[K     |███                             | 174kB 7.9MB/s eta 0:00:01\r\u001b[K     |███▎                            | 184kB 7.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 194kB 7.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 204kB 7.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 215kB 7.9MB/s eta 0:00:01\r\u001b[K     |████                            | 225kB 7.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 235kB 7.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 245kB 7.9MB/s eta 0:00:01\r\u001b[K     |████▌                           | 256kB 7.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 266kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 276kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 286kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 296kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 307kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 317kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 327kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 337kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 348kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 358kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 368kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 378kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 389kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 399kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 409kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 419kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 430kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 440kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 450kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 460kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 471kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 481kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 491kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 501kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 512kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 522kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 532kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 542kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 552kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 563kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 573kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 583kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 593kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 604kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 614kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 624kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 634kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 645kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 655kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 665kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 675kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 686kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 696kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 706kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 716kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 727kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 737kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 747kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 757kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 768kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 778kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 788kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 798kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 808kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 819kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 829kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 839kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 849kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 860kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 870kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 880kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 890kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 901kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 911kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 921kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 931kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 942kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 952kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 962kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 972kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 983kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 993kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.0MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.0MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.0MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.0MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.0MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.1MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.1MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.1MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.1MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.1MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.1MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.1MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.2MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.2MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.2MB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.2MB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.2MB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.2MB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.2MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.2MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.3MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.3MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.3MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.3MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.3MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.3MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.3MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.3MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.3MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.4MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.4MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.4MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.4MB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.4MB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.4MB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.4MB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.4MB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.5MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.5MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.5MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.5MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.5MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.5MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.5MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.6MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.6MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.6MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.6MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.6MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.6MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.6MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.6MB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.6MB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.6MB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.7MB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.7MB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.7MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.7MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.7MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.7MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.7MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.7MB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.7MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.8MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.8MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.8MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.8MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8MB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/4a/a54b254f67d8f4052338d54ebe90126f200693440a93ef76d254d581e3ec/sentry_sdk-1.1.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 32.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (8.0.0)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/da/6f6224fdfc47dab57881fe20c0d1bc3122be290198ba0bf26a953a045d92/GitPython-3.1.17-py3-none-any.whl (166kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 33.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.1.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pathtools, subprocess32\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=9ccbbde5d1fce67e8aa6c6d64068eec4d614f2c63b1d0fc2a678f63c670e2e1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=51e64aa62f517612edd9e0d1c9c5fc88621f3729d2de22703e1bfaee3acb6ffe\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "Successfully built pathtools subprocess32\n",
            "Installing collected packages: shortuuid, pathtools, docker-pycreds, sentry-sdk, subprocess32, configparser, smmap, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.17 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.1.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc7e7d50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07467a3e-3d48-4804-9908-8d8a8242b066"
      },
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 100000  # Number of samples to train on.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the data txt file on google drive.\n",
        "\n",
        "data_path = \"/content/drive/My Drive/lexicons/hi.translit.sampled.train.tsv\""
      ],
      "id": "bc7e7d50",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85daee71"
      },
      "source": [
        ""
      ],
      "id": "85daee71",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f72cfe82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8256781d-34e4-4c42-8733-0b952eb1cb89"
      },
      "source": [
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split(\"\\t\")\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    input_text = \"\\t\" + input_text + \" \" + \"\\n\" \n",
        "    target_text = \"\\t\" + target_text + \" \" + \"\\n\"\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n"
      ],
      "id": "f72cfe82",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 44204\n",
            "Number of unique input tokens: 66\n",
            "Number of unique output tokens: 29\n",
            "Max sequence length for inputs: 22\n",
            "Max sequence length for outputs: 23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4XUhdX5Yl-D"
      },
      "source": [
        ""
      ],
      "id": "V4XUhdX5Yl-D",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98263c0f"
      },
      "source": [
        "#Defining sweep config\n",
        "sweep_config = {\n",
        "    'name'  : \"Surya_Pratik\", \n",
        "    'method': 'grid', \n",
        "    'metric': {\n",
        "      'name': 'val_acc',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "\n",
        "    'parameters': {\n",
        "\n",
        "        'latent_dim': {\n",
        "            'values': [128,256,512]\n",
        "        },\n",
        "        'epochs': {\n",
        "            'values': [10,15]\n",
        "        },\n",
        "        'num_encoder': {\n",
        "            'values': [1,2,3]\n",
        "        },\n",
        "        'num_decoder': {\n",
        "            'values': [1,2,3]\n",
        "        },\n",
        "        'n_type': {\n",
        "            'values': ['lstm','rnn','gru']\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': ['0.2','null']\n",
        "        }\n",
        "        \n",
        "        \n",
        "    }\n",
        "}\n",
        "\n"
      ],
      "id": "98263c0f",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11cc16fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "873353a398f64445a8c708575addca68",
            "45810182e2454462804fba3d4cad252e",
            "484dd557428a42398d257c1d56fc86c6",
            "6b8abdac093d4a6b8168913eda52d321",
            "cb1969c6569543749443e1ed0f5adf13",
            "9c5e17da8c754e2b8c8c53e97ca2cd95",
            "4843974f48e0493d876241cad175035e",
            "17773eb6051f4c7b935210fb1a3915fd"
          ]
        },
        "outputId": "ee31a10e-4a9b-47e3-b70b-7f21eb71b6e1"
      },
      "source": [
        "#Defining the model\n",
        "sweep_id = wandb.sweep(sweep_config, project = \"dl_assignment3-surya-pratik\")\n",
        "def mytrain():\n",
        "  # Vectorize the data.\n",
        "    wandb.init(config = sweep_config)\n",
        "    config = wandb.config\n",
        "    \n",
        "    \n",
        "    encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
        "\n",
        "    if config.num_encoder==1:\n",
        "        if config.n_type=='lstm':\n",
        "            encoder_outputs0,state_h,state_c= keras.layers.LSTM(config.latent_dim, return_state=True)(encoder_inputs)\n",
        "            encoder_states = [state_h, state_c]\n",
        "        elif config.n_type=='gru':\n",
        "            encoder_outputs0,encoder_states= keras.layers.GRU(config.latent_dim, return_state=True)(encoder_inputs)\n",
        "        elif config.n_type=='rnn':\n",
        "            encoder_outputs0,encoder_states= keras.layers.SimpleRNN(config.latent_dim, return_state=True)(encoder_inputs)\n",
        "    \n",
        "    if config.num_encoder==2:\n",
        "        if config.n_type=='lstm':\n",
        "            encoder_outputs0= keras.layers.LSTM(config.latent_dim, return_sequences=True)(encoder_inputs)\n",
        "            encoder_outputs1,state_h,state_c= keras.layers.LSTM(config.latent_dim, return_state=True)(encoder_outputs0)\n",
        "            encoder_states = [state_h, state_c]\n",
        "        elif config.n_type=='gru':\n",
        "            encoder_outputs0= keras.layers.GRU(config.latent_dim, return_sequences=True)(encoder_inputs)\n",
        "            encoder_outputs1,encoder_states= keras.layers.GRU(config.latent_dim, return_state=True)(encoder_outputs0)\n",
        "        elif config.n_type=='rnn':\n",
        "            encoder_outputs0= keras.layers.SimpleRNN(config.latent_dim, return_sequences=True)(encoder_inputs)\n",
        "            encoder_outputs1,encoder_states= keras.layers.SimpleRNN(config.latent_dim, return_state=True)(encoder_outputs0)\n",
        "\n",
        "\n",
        "    if config.num_encoder==3:\n",
        "        if config.n_type=='lstm':\n",
        "            encoder_outputs0= keras.layers.LSTM(config.latent_dim, return_sequences=True)(encoder_inputs)\n",
        "            encoder_outputs1= keras.layers.LSTM(config.latent_dim, return_sequences=True)(encoder_outputs0)\n",
        "            encoder_outputs2,state_h,state_c= keras.layers.LSTM(config.latent_dim, return_state=True)(encoder_outputs1)\n",
        "            encoder_states = [state_h, state_c]\n",
        "        elif config.n_type=='gru':\n",
        "            encoder_outputs0= keras.layers.GRU(config.latent_dim, return_sequences=True)(encoder_inputs)\n",
        "            encoder_outputs1= keras.layers.GRU(config.latent_dim, return_sequences=True)(encoder_outputs0)\n",
        "            encoder_outputs2,encoder_states= keras.layers.GRU(config.latent_dim, return_state=True)(encoder_outputs1)\n",
        "        elif config.n_type=='rnn':\n",
        "            encoder_outputs0= keras.layers.SimpleRNN(config.latent_dim, return_sequences=True)(encoder_inputs)\n",
        "            encoder_outputs1= keras.layers.SimpleRNN(config.latent_dim, return_sequences=True)(encoder_outputs0)\n",
        "            encoder_outputs2,encoder_states= keras.layers.SimpleRNN(config.latent_dim, return_state=True)(encoder_outputs1)\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
        "\n",
        "\n",
        "    if config.num_decoder==1:\n",
        "        if config.n_type=='lstm':\n",
        "            decoder_outputs,_,_ = keras.layers.LSTM(config.latent_dim, return_sequences=True, return_state=True)(decoder_inputs, initial_state=encoder_states)\n",
        "            \n",
        "        elif config.n_type=='gru':\n",
        "            decoder_outputs,_ = keras.layers.GRU(config.latent_dim, return_sequences=True, return_state=True)(decoder_inputs, initial_state=encoder_states)\n",
        "        elif config.n_type=='rnn':\n",
        "            decoder_outputs,_ = keras.layers.SimpleRNN(config.latent_dim, return_sequences=True, return_state=True)(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "\n",
        "    if config.num_decoder==2:\n",
        "        if config.n_type=='lstm':\n",
        "            decoder_outputs0, _ , _ = keras.layers.LSTM(config.latent_dim, return_sequences=True, return_state=True)(decoder_inputs, initial_state=encoder_states)\n",
        "            decoder_outputs , _ , _      = keras.layers.LSTM(config.latent_dim, return_sequences=True, return_state=True)(decoder_outputs0)\n",
        "        elif config.n_type=='gru':\n",
        "            decoder_outputs0, _  = keras.layers.GRU(config.latent_dim, return_sequences=True, return_state=True)(decoder_inputs, initial_state=encoder_states)\n",
        "            decoder_outputs , _       = keras.layers.GRU(config.latent_dim, return_sequences=True, return_state=True)(decoder_outputs0)\n",
        "        elif config.n_type=='rnn':\n",
        "            decoder_outputs0, _  = keras.layers.SimpleRNN(config.latent_dim, return_sequences=True, return_state=True)(decoder_inputs, initial_state=encoder_states)\n",
        "            decoder_outputs , _       = keras.layers.SimpleRNN(config.latent_dim, return_sequences=True, return_state=True)(decoder_outputs0)\n",
        "\n",
        "\n",
        "    if config.num_decoder==3:\n",
        "        if config.n_type=='lstm':\n",
        "            decoder_outputs0, _ , _ = keras.layers.LSTM(config.latent_dim, return_sequences=True, return_state=True)(decoder_inputs, initial_state=encoder_states)\n",
        "            decoder_outputs1, _ , _ = keras.layers.LSTM(config.latent_dim, return_sequences=True, return_state=True)(decoder_outputs0)\n",
        "            decoder_outputs ,_, _   = keras.layers.LSTM(config.latent_dim, return_sequences=True, return_state=True)(decoder_outputs1)\n",
        "        elif config.n_type=='gru':\n",
        "            decoder_outputs0, _  = keras.layers.GRU(config.latent_dim, return_sequences=True, return_state=True)(decoder_inputs, initial_state=encoder_states)\n",
        "            decoder_outputs1, _  = keras.layers.GRU(config.latent_dim, return_sequences=True, return_state=True)(decoder_outputs0)\n",
        "            decoder_outputs ,_   = keras.layers.GRU(config.latent_dim, return_sequences=True, return_state=True)(decoder_outputs1)\n",
        "        elif config.n_type=='rnn':\n",
        "            decoder_outputs0, _  = keras.layers.SimpleRNN(config.latent_dim, return_sequences=True, return_state=True)(decoder_inputs, initial_state=encoder_states)\n",
        "            decoder_outputs1, _  = keras.layers.SimpleRNN(config.latent_dim, return_sequences=True, return_state=True)(decoder_outputs0)\n",
        "            decoder_outputs ,_   = keras.layers.SimpleRNN(config.latent_dim, return_sequences=True, return_state=True)(decoder_outputs1)\n",
        "    if config.dropout=='0.2':        \n",
        "        decoder_outputs=keras.layers.Dropout(0.1)(decoder_outputs)\n",
        "    decoder_outputs =  keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")(decoder_outputs)\n",
        "    model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "    model.summary()\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=config.epochs,\n",
        "    validation_split=0.2,callbacks=[WandbCallback()])\n",
        "    model.save(\"s2s\")\n",
        "wandb.agent(sweep_id, mytrain)"
      ],
      "id": "11cc16fe",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: dcd3i3o7\n",
            "Sweep URL: https://wandb.ai/ee20m018/dl_assignment3-surya-pratik/sweeps/dcd3i3o7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d52y76nl with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_type: lstm\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mee20m018\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.30<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">ruby-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/ee20m018/dl_assignment3-surya-pratik\" target=\"_blank\">https://wandb.ai/ee20m018/dl_assignment3-surya-pratik</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/ee20m018/dl_assignment3-surya-pratik/sweeps/dcd3i3o7\" target=\"_blank\">https://wandb.ai/ee20m018/dl_assignment3-surya-pratik/sweeps/dcd3i3o7</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/ee20m018/dl_assignment3-surya-pratik/runs/d52y76nl\" target=\"_blank\">https://wandb.ai/ee20m018/dl_assignment3-surya-pratik/runs/d52y76nl</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210524_133707-d52y76nl</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 66)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, None, 256)    330752      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 29)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 256), (None, 525312      lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 256),  292864      input_2[0][0]                    \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 256),  525312      lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, None, 256)    0           lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 29)     7453        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,681,693\n",
            "Trainable params: 1,681,693\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/15\n",
            "553/553 [==============================] - 35s 23ms/step - loss: 1.1260 - accuracy: 0.7005 - val_loss: 0.9062 - val_accuracy: 0.7633\n",
            "Epoch 2/15\n",
            "553/553 [==============================] - 10s 18ms/step - loss: 0.6730 - accuracy: 0.7981 - val_loss: 0.7322 - val_accuracy: 0.8086\n",
            "Epoch 3/15\n",
            "553/553 [==============================] - 10s 19ms/step - loss: 0.4429 - accuracy: 0.8622 - val_loss: 0.5523 - val_accuracy: 0.8362\n",
            "Epoch 4/15\n",
            "553/553 [==============================] - 10s 18ms/step - loss: 0.3067 - accuracy: 0.9051 - val_loss: 0.4472 - val_accuracy: 0.8611\n",
            "Epoch 5/15\n",
            "553/553 [==============================] - 10s 18ms/step - loss: 0.2356 - accuracy: 0.9274 - val_loss: 0.3626 - val_accuracy: 0.8840\n",
            "Epoch 6/15\n",
            "553/553 [==============================] - 10s 18ms/step - loss: 0.1908 - accuracy: 0.9406 - val_loss: 0.3057 - val_accuracy: 0.9021\n",
            "Epoch 7/15\n",
            "553/553 [==============================] - 10s 18ms/step - loss: 0.1655 - accuracy: 0.9483 - val_loss: 0.2694 - val_accuracy: 0.9143\n",
            "Epoch 8/15\n",
            "553/553 [==============================] - 10s 18ms/step - loss: 0.1462 - accuracy: 0.9534 - val_loss: 0.2510 - val_accuracy: 0.9224\n",
            "Epoch 9/15\n",
            "553/553 [==============================] - 10s 18ms/step - loss: 0.1350 - accuracy: 0.9560 - val_loss: 0.2301 - val_accuracy: 0.9279\n",
            "Epoch 10/15\n",
            "553/553 [==============================] - 10s 18ms/step - loss: 0.1232 - accuracy: 0.9593 - val_loss: 0.2351 - val_accuracy: 0.9274\n",
            "Epoch 11/15\n",
            "553/553 [==============================] - 10s 18ms/step - loss: 0.1159 - accuracy: 0.9610 - val_loss: 0.2256 - val_accuracy: 0.9297\n",
            "Epoch 12/15\n",
            "553/553 [==============================] - 10s 18ms/step - loss: 0.1104 - accuracy: 0.9622 - val_loss: 0.2242 - val_accuracy: 0.9304\n",
            "Epoch 13/15\n",
            "553/553 [==============================] - 10s 19ms/step - loss: 0.1026 - accuracy: 0.9643 - val_loss: 0.2242 - val_accuracy: 0.9306\n",
            "Epoch 14/15\n",
            "553/553 [==============================] - 10s 18ms/step - loss: 0.0981 - accuracy: 0.9653 - val_loss: 0.2265 - val_accuracy: 0.9296\n",
            "Epoch 15/15\n",
            "553/553 [==============================] - 10s 18ms/step - loss: 0.0936 - accuracy: 0.9663 - val_loss: 0.2296 - val_accuracy: 0.9291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: s2s/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: s2s/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 349<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "873353a398f64445a8c708575addca68",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 19.31MB of 19.31MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210524_133707-d52y76nl/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210524_133707-d52y76nl/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>14</td></tr><tr><td>loss</td><td>0.09609</td></tr><tr><td>accuracy</td><td>0.96547</td></tr><tr><td>val_loss</td><td>0.2296</td></tr><tr><td>val_accuracy</td><td>0.9291</td></tr><tr><td>_runtime</td><td>186</td></tr><tr><td>_timestamp</td><td>1621863613</td></tr><tr><td>_step</td><td>14</td></tr><tr><td>best_val_loss</td><td>0.22424</td></tr><tr><td>best_epoch</td><td>11</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>loss</td><td>█▅▄▃▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▃▅▆▇▇▇████████</td></tr><tr><td>val_loss</td><td>█▆▄▃▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▅▆▇▇████████</td></tr><tr><td>_runtime</td><td>▁▁▂▂▃▃▄▄▅▆▆▆▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▃▃▄▄▅▆▆▆▇██</td></tr><tr><td>_step</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">ruby-sweep-1</strong>: <a href=\"https://wandb.ai/ee20m018/dl_assignment3-surya-pratik/runs/d52y76nl\" target=\"_blank\">https://wandb.ai/ee20m018/dl_assignment3-surya-pratik/runs/d52y76nl</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2406561",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6dde723-bb48-421f-a766-8446ab80876e"
      },
      "source": [
        "##################################\n",
        "#Preprocessing test data\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "test_data_path = \"/content/drive/My Drive/lexicons/hi.translit.sampled.test.tsv\"\n",
        "\n",
        "\n",
        "with open(test_data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split(\"\\t\")\n",
        "    input_text = \"\\t\" + input_text + \" \" + \"\\n\" \n",
        "    target_text = \"\\t\" + target_text + \" \" + \"\\n\"\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n"
      ],
      "id": "f2406561",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 4502\n",
            "Number of unique input tokens: 66\n",
            "Number of unique output tokens: 29\n",
            "Max sequence length for inputs: 22\n",
            "Max sequence length for outputs: 23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91BYlGdktvM2",
        "outputId": "3c5a2d9b-3cdf-4247-c00b-e3297fbec4c4"
      },
      "source": [
        "#Evaluating the test model\n",
        "model = keras.models.load_model(\"/content/drive/My Drive/lexicons/a.h2s\")\n",
        "test_pred=model.predict([encoder_input_data, decoder_input_data])\n",
        "print(model.evaluate([encoder_input_data, decoder_input_data],decoder_target_data))"
      ],
      "id": "91BYlGdktvM2",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "141/141 [==============================] - 2s 7ms/step - loss: 0.1437 - accuracy: 0.9545\n",
            "[0.1436898559331894, 0.9545226097106934]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a52f2569",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19d4ea07-9f50-438d-d2da-d7b9d689f171"
      },
      "source": [
        "model.save(\"/content/drive/My Drive/lexicons/a.h2s\")"
      ],
      "id": "a52f2569",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/lexicons/a.h2s/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/lexicons/a.h2s/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42822a4d"
      },
      "source": [
        ""
      ],
      "id": "42822a4d",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUXb4nYb882R"
      },
      "source": [
        ""
      ],
      "id": "TUXb4nYb882R",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcI3lQygD7SS"
      },
      "source": [
        ""
      ],
      "id": "ZcI3lQygD7SS",
      "execution_count": 7,
      "outputs": []
    }
  ]
}