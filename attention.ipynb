{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "dl asssigment nowandb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhnVjkkG6J9B"
      },
      "source": [
        "#!pip install wandb\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#import wandb\n",
        "#from wandb.keras import WandbCallback\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvYpqcvl6NOK",
        "outputId": "cc6945c0-2baf-4aa9-d635-13a9675fd286"
      },
      "source": [
        "\n",
        "num_samples = 100000  # Number of samples to train on.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the data txt file on google drive.\n",
        "\n",
        "data_path = \"/content/drive/My Drive/lexicons/hi.translit.sampled.train.tsv\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVtCHjRT6Rl_"
      },
      "source": [
        "# Vectorize the data.\n",
        "\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split(\"\\t\")\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    input_text = \"\\t\" + input_text + \" \" + \"\\n\" \n",
        "    target_text = \"\\t\" + target_text + \" \" + \"\\n\"\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCvrTkOQzQn2"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-db3KdCDW3o"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "\n",
        "  w = w.strip()\n",
        "  k=''\n",
        "  for i in w:\n",
        "    k=k+' '+ i\n",
        "\n",
        "\n",
        "  w = '<start> ' + k + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTgE-VoDDpsy"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWJ_M6zxD3T2"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyEgkMtr-xFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10b73033-5ecb-4b86-98c7-62853228e390"
      },
      "source": [
        "\n",
        "\n",
        "#Preprocessing the input and output\n",
        "hii=input_texts\n",
        "eni=target_texts\n",
        "en=[]\n",
        "hi=[]\n",
        "for i in eni:\n",
        "  en.append(preprocess_sentence(i))\n",
        "print(en[:10])\n",
        "for i in hii:\n",
        "  hi.append(preprocess_sentence(i))\n",
        "\n",
        "\n",
        "print(hi[:10])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<start>  a n <end>', '<start>  a n k g a n i t <end>', '<start>  u n c l e <end>', '<start>  a n k u r <end>', '<start>  a n k u r a n <end>', '<start>  a n k u r i t <end>', '<start>  a a n k u s h <end>', '<start>  a n k u s h <end>', '<start>  a n g <end>', '<start>  a n g a <end>']\n",
            "['<start>  अ ं <end>', '<start>  अ ं क ग ण ि त <end>', '<start>  अ ं क ल <end>', '<start>  अ ं क ु र <end>', '<start>  अ ं क ु र ण <end>', '<start>  अ ं क ु र ि त <end>', '<start>  अ ं क ु श <end>', '<start>  अ ं क ु श <end>', '<start>  अ ं ग <end>', '<start>  अ ं ग <end>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxgzVNl1FNaa"
      },
      "source": [
        "#vectorizing the input and output\n",
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer\n",
        "input_tensor, inp_lang = tokenize(hi)\n",
        "target_tensor, targ_lang = tokenize(en)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYEgaaifFUE8"
      },
      "source": [
        "#Getting the max length\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qG34PJbUFoSy",
        "outputId": "8fb57d30-467c-42b8-e986-45363e0ac57d"
      },
      "source": [
        "#Spliting the data\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35363 35363 8841 8841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JujNYXDaD8w3"
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t != 0:\n",
        "      print(f'{t} ----> {lang.index_word[t]}')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c7gs6GwFx3p",
        "outputId": "645048f6-5c79-4f6a-df0e-307e6f7b6be7"
      },
      "source": [
        "#Printing the vector\n",
        "print(\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[1])\n",
        "print()\n",
        "print(\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "4 ----> र\n",
            "19 ----> ो\n",
            "16 ----> व\n",
            "4 ----> र\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "2 ----> <start>\n",
            "7 ----> r\n",
            "11 ----> o\n",
            "19 ----> v\n",
            "10 ----> e\n",
            "7 ----> r\n",
            "3 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axlJ8J1DGHRo"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M65GPrmYGThY"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYDjhRycGYA1"
      },
      "source": [
        "#Encoder class\n",
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yAqdSI9GaLE"
      },
      "source": [
        "#encoder object\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHDrlO25Gevl"
      },
      "source": [
        "#Attention class\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlGH4AJgGhRc"
      },
      "source": [
        "#Attention object with 10 units\n",
        "attention_layer = BahdanauAttention(10)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npJMOvVRGkzv"
      },
      "source": [
        "#Decoder class\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N72pGQC8Gk2c"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZk2QfuEGk5U"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                            reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQW9nlNnGk7r"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njXExTzfGk-j"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC1kLBloGlB7",
        "outputId": "a51528b7-1775-4c84-a003-c654e0d78c92"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print(f'Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy():.4f}')\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "  print(f'Epoch {epoch+1} Loss {total_loss/steps_per_epoch:.4f}')\n",
        "  print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 1.2556\n",
            "Epoch 1 Batch 100 Loss 0.8807\n",
            "Epoch 1 Batch 200 Loss 0.4637\n",
            "Epoch 1 Batch 300 Loss 0.2286\n",
            "Epoch 1 Batch 400 Loss 0.2454\n",
            "Epoch 1 Batch 500 Loss 0.1920\n",
            "Epoch 1 Loss 0.4630\n",
            "Time taken for 1 epoch 67.38 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.1903\n",
            "Epoch 2 Batch 100 Loss 0.1777\n",
            "Epoch 2 Batch 200 Loss 0.1694\n",
            "Epoch 2 Batch 300 Loss 0.1520\n",
            "Epoch 2 Batch 400 Loss 0.2151\n",
            "Epoch 2 Batch 500 Loss 0.1340\n",
            "Epoch 2 Loss 0.1729\n",
            "Time taken for 1 epoch 50.31 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.1488\n",
            "Epoch 3 Batch 100 Loss 0.2569\n",
            "Epoch 3 Batch 200 Loss 0.1900\n",
            "Epoch 3 Batch 300 Loss 0.1339\n",
            "Epoch 3 Batch 400 Loss 0.1367\n",
            "Epoch 3 Batch 500 Loss 0.1589\n",
            "Epoch 3 Loss 0.1780\n",
            "Time taken for 1 epoch 49.94 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.1094\n",
            "Epoch 4 Batch 100 Loss 0.1174\n",
            "Epoch 4 Batch 200 Loss 0.1167\n",
            "Epoch 4 Batch 300 Loss 0.1363\n",
            "Epoch 4 Batch 400 Loss 0.1937\n",
            "Epoch 4 Batch 500 Loss 0.1493\n",
            "Epoch 4 Loss 0.1439\n",
            "Time taken for 1 epoch 50.26 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.1148\n",
            "Epoch 5 Batch 100 Loss 0.1343\n",
            "Epoch 5 Batch 200 Loss 0.1241\n",
            "Epoch 5 Batch 300 Loss 0.1439\n",
            "Epoch 5 Batch 400 Loss 0.1055\n",
            "Epoch 5 Batch 500 Loss 0.1380\n",
            "Epoch 5 Loss 0.1282\n",
            "Time taken for 1 epoch 49.95 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.1477\n",
            "Epoch 6 Batch 100 Loss 0.0903\n",
            "Epoch 6 Batch 200 Loss 0.1636\n",
            "Epoch 6 Batch 300 Loss 0.1432\n",
            "Epoch 6 Batch 400 Loss 0.1374\n",
            "Epoch 6 Batch 500 Loss 0.1203\n",
            "Epoch 6 Loss 0.1250\n",
            "Time taken for 1 epoch 50.17 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.1173\n",
            "Epoch 7 Batch 100 Loss 0.1083\n",
            "Epoch 7 Batch 200 Loss 0.0866\n",
            "Epoch 7 Batch 300 Loss 0.1259\n",
            "Epoch 7 Batch 400 Loss 0.1473\n",
            "Epoch 7 Batch 500 Loss 0.1172\n",
            "Epoch 7 Loss 0.1121\n",
            "Time taken for 1 epoch 49.55 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.0979\n",
            "Epoch 8 Batch 100 Loss 0.0821\n",
            "Epoch 8 Batch 200 Loss 0.0883\n",
            "Epoch 8 Batch 300 Loss 0.1514\n",
            "Epoch 8 Batch 400 Loss 0.1076\n",
            "Epoch 8 Batch 500 Loss 0.1097\n",
            "Epoch 8 Loss 0.1055\n",
            "Time taken for 1 epoch 49.60 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0981\n",
            "Epoch 9 Batch 100 Loss 0.0928\n",
            "Epoch 9 Batch 200 Loss 0.0857\n",
            "Epoch 9 Batch 300 Loss 0.0902\n",
            "Epoch 9 Batch 400 Loss 0.1279\n",
            "Epoch 9 Batch 500 Loss 0.0948\n",
            "Epoch 9 Loss 0.0988\n",
            "Time taken for 1 epoch 49.19 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.1164\n",
            "Epoch 10 Batch 100 Loss 0.0828\n",
            "Epoch 10 Batch 200 Loss 0.0906\n",
            "Epoch 10 Batch 300 Loss 0.1182\n",
            "Epoch 10 Batch 400 Loss 0.1369\n",
            "Epoch 10 Batch 500 Loss 0.0991\n",
            "Epoch 10 Loss 0.1002\n",
            "Time taken for 1 epoch 49.80 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHeYdpO2JACB"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  #inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs=[]\n",
        "  for i in sentence.split(' '):\n",
        "    if i in inp_lang.word_index:\n",
        "      inputs.append(inp_lang.word_index[i])\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeGwtOt6JGtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95f6c6d-5b33-4c32-b633-42dce461b3e4"
      },
      "source": [
        "!pip install fonttools\n",
        "\n",
        "from matplotlib.font_manager import FontProperties\n",
        "\n",
        "\n",
        "#using hindi font for display\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  nirm = \"/content/drive/My Drive/lexicons/ARIALUNI.TTF\"\n",
        "  prop = FontProperties(fname=nirm)\n",
        "\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence,  rotation=90,fontproperties=prop)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fonttools in /usr/local/lib/python3.7/dist-packages (4.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpGqbVw9Gyl4"
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input:', sentence)\n",
        "  print('Predicted translation:', result)\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')),\n",
        "                                  :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "bmy7-zghJMk6",
        "outputId": "d24f12c6-9645-4f91-90db-552064ab9456"
      },
      "source": [
        "translate(input_texts[10])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start>  अ ं ग ् र ज ़ ी <end>\n",
            "Predicted translation: a n g r a j i <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-VYvuP3h1rT"
      },
      "source": [
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "data_path = \"/content/drive/My Drive/lexicons/hi.translit.sampled.test.tsv\"\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split(\"\\t\")\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    input_text = \"\\t\" + input_text + \" \" + \"\\n\" \n",
        "    target_text = \"\\t\" + target_text + \" \" + \"\\n\"\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd4ruD1zhRni",
        "outputId": "0cbf6c39-f1ba-4199-c4c6-5fb4a16cb71d"
      },
      "source": [
        "  print(len(input_texts[0]))\n",
        "  for sentence in input_texts[:10]:\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "    print('-')\n",
        "    print('Input sentence: \t', sentence)\n",
        "    print('Decoded sentence: ', result)\n",
        "    print('\\n')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "-\n",
            "Input sentence: \t <start>  अ ं क <end>\n",
            "Decoded sentence:  a n k <end> \n",
            "\n",
            "\n",
            "-\n",
            "Input sentence: \t <start>  अ ं क <end>\n",
            "Decoded sentence:  a n k <end> \n",
            "\n",
            "\n",
            "-\n",
            "Input sentence: \t <start>  अ ं क ि त <end>\n",
            "Decoded sentence:  a n k i t <end> \n",
            "\n",
            "\n",
            "-\n",
            "Input sentence: \t <start>  अ ं क ो ं <end>\n",
            "Decoded sentence:  a n k o n <end> \n",
            "\n",
            "\n",
            "-\n",
            "Input sentence: \t <start>  अ ं क ो ं <end>\n",
            "Decoded sentence:  a n k o n <end> \n",
            "\n",
            "\n",
            "-\n",
            "Input sentence: \t <start>  अ ं क ो ं <end>\n",
            "Decoded sentence:  a n k o n <end> \n",
            "\n",
            "\n",
            "-\n",
            "Input sentence: \t <start>  अ ं क ो र <end>\n",
            "Decoded sentence:  a n k o r e <end> \n",
            "\n",
            "\n",
            "-\n",
            "Input sentence: \t <start>  अ ं क ो र <end>\n",
            "Decoded sentence:  a n k o r e <end> \n",
            "\n",
            "\n",
            "-\n",
            "Input sentence: \t <start>  अ ं ग ा र क <end>\n",
            "Decoded sentence:  a n g a r k <end> \n",
            "\n",
            "\n",
            "-\n",
            "Input sentence: \t <start>  अ ं ग ा र क <end>\n",
            "Decoded sentence:  a n g a r k <end> \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C04eVNqSVxn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEVT_pg3SWNc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}